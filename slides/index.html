<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>R case study: web scraping</title>
    <meta charset="utf-8" />
    <meta name="author" content="John Little" />
    <meta name="date" content="2021-03-01" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/all.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/v4-shims.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="styles/my-theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# R case study: web scraping
### John Little
### 2021-03-01

---






## Duke University: Land Acknowledgement

I would like to take a moment to honor the land in Durham, NC.  Duke University sits on the ancestral lands of the Shakori, Eno and Catawba people. This institution of higher education is built on land stolen from those peoples.  These tribes were here before the colonizers arrived.  Additionally this land has borne witness to over 400 years of the enslavement, torture, and systematic mistreatment of African people and their descendants.  Recognizing this history is an honest attempt to breakout beyond persistent patterns of colonization and to rewrite the erasure of Indigenous and Black peoples.  There is value in acknowledging the history of our occupied spaces and places.  I hope we can glimpse an understanding of these histories by recognizing the origins of collective journeys.

---
## Demonstration Goals

- Building on earlier [Rfun workshops](https://rfun.library.duke.edu/)
- Web scraping is fundamentally a deconstruction process
- Introduce just enough HTML/CSS and HTTP
- Introduce the `library(rvest)` package for harvesting websites/HTML
- Tidyverse iteration with `purrr:map`
- Point out useful documentation &amp; resources 

.f7.i.moon-gray[This is not an research design or HTML design class. YMMV: data gathering and cleaning are vital and can be complex. This is a demonstration of leveraging the Tidyverse.]

### Caveats
- You will be as successful as the web author(s) were consistent 
- Read and follow the _Terms of Use_ for any target web host
- Read and honor the host's robots.txt | https://www.robotstxt.org
    - Always **pause** to avoid the perception of a _Denial of Service_ (DOS) attack
    


&lt;div class="footercc"&gt;
&lt;i class="fab fa-creative-commons"&gt;&lt;/i&gt;&amp;nbsp; &lt;i class="fab fa-creative-commons-by"&gt;&lt;/i&gt;&lt;i class="fab fa-creative-commons-nc"&gt;&lt;/i&gt;  &lt;a href = "https://JohnLittle.info"&gt;&lt;span class = "opacity30"&gt;https://&lt;/span&gt;JohnLittle&lt;span class = "opacity30"&gt;.info&lt;/span&gt;&lt;/a&gt; 
&lt;span class = "opacity30"&gt;&lt;a href="https://github.com/libjohn/workshop_webscraping"&gt;https://github.com/libjohn/workshop_webscraping&lt;/a&gt; | 2021-03-01 &lt;/span&gt;
&lt;/div&gt;




---
class:middle

.left-column[
### Scraping 

.f6[Gather or ingest web page data for analysis]

![scraping bee propolis](images/Scraping_propolis.jpg "scraping propolis")
&amp;nbsp;  
`rvest::`  
`read_html()`

]

.right-column[

**&lt;span text-align: left;&gt;Crawling&lt;span&gt; &lt;span text-align: center;&gt;+&lt;/span&gt; &lt;span text-align:right;&gt;Parsing&lt;/span&gt;**

&lt;div class = "container" id = "imgspcl" style="width: 100%; max-width: 100%;"&gt;
&lt;img src = "images/crawling_med.jpg" width = "50%"&gt; &amp;nbsp; + &amp;nbsp; &lt;img src = "images/strain_comb.jpg" width="50%"&gt;
&lt;/div&gt;



.pull-left[
.f7[Systematically iterating through a website, gathering data from more than one page (URL)]

`purrr::map()`
]

.pull-right[
.f7[Separating the syntactic elements of the HTML.  Keeping only the data you need]

`rvest::html_nodes()`  
`rvest::html_text()`  
`rvest::html_attr()`
]


]




&lt;div class="footercc"&gt;
&lt;i class="fab fa-creative-commons"&gt;&lt;/i&gt;&amp;nbsp; &lt;i class="fab fa-creative-commons-by"&gt;&lt;/i&gt;&lt;i class="fab fa-creative-commons-nc"&gt;&lt;/i&gt;  &lt;a href = "https://JohnLittle.info"&gt;&lt;span class = "opacity30"&gt;https://&lt;/span&gt;JohnLittle&lt;span class = "opacity30"&gt;.info&lt;/span&gt;&lt;/a&gt; 
&lt;span class = "opacity30"&gt;&lt;a href="https://github.com/libjohn/workshop_webscraping"&gt;https://github.com/libjohn/workshop_webscraping&lt;/a&gt; | 2021-03-01 &lt;/span&gt;
&lt;/div&gt;





---
## HTML

Hypter Text Markup Language

```html
&lt;html&gt;
  &lt;body&gt;
  
    &lt;h1&gt;My First Heading&lt;/h1&gt;
    &lt;p&gt;My first paragraph. contains a 
    &lt;a href="https://www.w3schools.com"&gt;link&lt;/a&gt; to
    W3schools.com
    &lt;/p&gt;
  
  &lt;/body&gt;
&lt;/html&gt;

```



&lt;div class="footercc"&gt;
&lt;i class="fab fa-creative-commons"&gt;&lt;/i&gt;&amp;nbsp; &lt;i class="fab fa-creative-commons-by"&gt;&lt;/i&gt;&lt;i class="fab fa-creative-commons-nc"&gt;&lt;/i&gt;  &lt;a href = "https://JohnLittle.info"&gt;&lt;span class = "opacity30"&gt;https://&lt;/span&gt;JohnLittle&lt;span class = "opacity30"&gt;.info&lt;/span&gt;&lt;/a&gt; 
&lt;span class = "opacity30"&gt;&lt;a href="https://github.com/libjohn/workshop_webscraping"&gt;https://github.com/libjohn/workshop_webscraping&lt;/a&gt; | 2021-03-01 &lt;/span&gt;
&lt;/div&gt;



---
## CSS

Cascading Style Sheets

```css

&lt;html&gt;
&lt;body&gt;

  &lt;div class=”abc”&gt;  &lt;/div&gt;
  
  &lt;div id=”xyz”&gt; &lt;/div&gt;

&lt;/body&gt;
&lt;/html&gt;

```

http://www.vondel.humanities.uva.nl/style.css




&lt;div class="footercc"&gt;
&lt;i class="fab fa-creative-commons"&gt;&lt;/i&gt;&amp;nbsp; &lt;i class="fab fa-creative-commons-by"&gt;&lt;/i&gt;&lt;i class="fab fa-creative-commons-nc"&gt;&lt;/i&gt;  &lt;a href = "https://JohnLittle.info"&gt;&lt;span class = "opacity30"&gt;https://&lt;/span&gt;JohnLittle&lt;span class = "opacity30"&gt;.info&lt;/span&gt;&lt;/a&gt; 
&lt;span class = "opacity30"&gt;&lt;a href="https://github.com/libjohn/workshop_webscraping"&gt;https://github.com/libjohn/workshop_webscraping&lt;/a&gt; | 2021-03-01 &lt;/span&gt;
&lt;/div&gt;




---
## Procedure

The basic workflow of web scraping is

1. Development

    - Import raw HTML of a single target page (page detail, or “leaf”)
    - Parse the HTML of the test page to gather the data you want
    - Check robots.txt, terms of use
    - In a web browser, manually browse and understand the site navigation of the scrape target (site navigation, or “branches”)
    - Parse the site navigation and develop an interation plan
    - Iterate: write code that implements iteration, i.e. automated page crawling
    - Perform a dry run with a limited subset of the target web site
    - Construct time pauses (to avoid DNS attacks)
    - Production

1. Iterate

    - Crawl the site navigation (branches)
    - Parse HTML for each detail page (leaves)



&lt;div class="footercc"&gt;
&lt;i class="fab fa-creative-commons"&gt;&lt;/i&gt;&amp;nbsp; &lt;i class="fab fa-creative-commons-by"&gt;&lt;/i&gt;&lt;i class="fab fa-creative-commons-nc"&gt;&lt;/i&gt;  &lt;a href = "https://JohnLittle.info"&gt;&lt;span class = "opacity30"&gt;https://&lt;/span&gt;JohnLittle&lt;span class = "opacity30"&gt;.info&lt;/span&gt;&lt;/a&gt; 
&lt;span class = "opacity30"&gt;&lt;a href="https://github.com/libjohn/workshop_webscraping"&gt;https://github.com/libjohn/workshop_webscraping&lt;/a&gt; | 2021-03-01 &lt;/span&gt;
&lt;/div&gt;



---
background-image: url(images/selector_graph.png)




&lt;div class="footercc"&gt;
&lt;i class="fab fa-creative-commons"&gt;&lt;/i&gt;&amp;nbsp; &lt;i class="fab fa-creative-commons-by"&gt;&lt;/i&gt;&lt;i class="fab fa-creative-commons-nc"&gt;&lt;/i&gt;  &lt;a href = "https://JohnLittle.info"&gt;&lt;span class = "opacity30"&gt;https://&lt;/span&gt;JohnLittle&lt;span class = "opacity30"&gt;.info&lt;/span&gt;&lt;/a&gt; 
&lt;span class = "opacity30"&gt;&lt;a href="https://github.com/libjohn/workshop_webscraping"&gt;https://github.com/libjohn/workshop_webscraping&lt;/a&gt; | 2021-03-01 &lt;/span&gt;
&lt;/div&gt;



---
class:  middle, center

.bg-washed-blue.b--navy.ba.bw2.br3.shadow-5.ph4.mt5[

## John R Little

.f5.blue[Data Science Librarian  
Center for Data &amp; Visualization Sciences  
Duke University Libraries  
]

.f7[https://johnlittle.info]  
.f7[https://Rfun.library.duke.edu]  
.f7[https://library.duke.edu/data]
]

&lt;i class="fab fa-creative-commons fa-2x"&gt;&lt;/i&gt; &amp;nbsp; &lt;i class="fab fa-creative-commons-by fa-2x"&gt;&lt;/i&gt;&lt;i class="fab fa-creative-commons-nc fa-2x"&gt;&lt;/i&gt;  
.f6.moon-gray[Creative Commons:  Attribution-NonCommercial 4.0]  
.f7.moon-gray[https://creativecommons.org/licenses/by-nc/4.0]




    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
